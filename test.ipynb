{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDS = \"neural-hour-421815-d95e4bee266b.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(CREDS)\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/var/folders/wx/4zj8vyds7kv6w4t2k82r4lcr0000gn/T/ipykernel_56835/1184840066.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DtypeWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Columns </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\"> have mixed types. Specify dtype option on import or set </span><span style=\"color: #808000; text-decoration-color: #808000\">low_memory</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">False</span><span style=\"color: #808000; text-decoration-color: #808000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/var/folders/wx/4zj8vyds7kv6w4t2k82r4lcr0000gn/T/ipykernel_56835/\u001b[0m\u001b[1;33m1184840066.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m2\u001b[0m\u001b[1;33m DtypeWarning\u001b[0m\u001b[33m: Columns \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m have mixed types. Specify dtype option on import or set \u001b[0m\u001b[33mlow_memory\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mFalse\u001b[0m\u001b[33m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_file_path = \"ETL/01_Data_Collection/01_dataset/processed_data/filtered_df3.csv\"\n",
    "df = pd.read_csv(df_file_path)\n",
    "df['block'] = df['block'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_id = ['flat_type', 'flat_model', 'flat_type_model',\n",
    "                  'floor_area_sqm', 'lease_commence_date', 'storey_range',\n",
    "                  'avg_storey_range', 'total_dwelling_units']\n",
    "        \n",
    "address_id = ['postal','address', 'town', 'block', 'street_name', \n",
    "                                'planning_area', 'latitude', 'longitude']\n",
    "        \n",
    "surroundings_id = ['commercial', 'market_hawker', 'multistorey_carpark', 'precinct_pavilion',\n",
    "                        'mall_nearest_distance', 'hawker_nearest_distance',\n",
    "                                    'hawker_food_stalls', 'hawker_market_stalls', 'mrt_nearest_distance', 'mrt_name', 'bus_interchange', 'mrt_interchange', 'bus_stop_nearest_distance', 'bus_stop_name',\n",
    "                                    'pri_sch_nearest_distance', 'pri_sch_name', 'vacancy', 'pri_sch_affiliation',\n",
    "                                    'sec_sch_nearest_dist', 'sec_sch_name', 'cutoff_point', 'affiliation', 'school_type',\n",
    "                                    'bus_stop_proximity', 'mrt_proximity', 'pri_sch_proximity', 'sec_sch_proximity']\n",
    "transaction_id = ['month', 'year', 'quarter', 'inflation', 'normalized_resale_price']\n",
    "\n",
    "\n",
    "property_df = df[property_id].copy().drop_duplicates()\n",
    "property_df[\"property_id\"] = [i for i in range(1 , len(property_df) + 1)]\n",
    "\n",
    "address_df = df[address_id].copy().drop_duplicates()\n",
    "address_df[\"address_id\"] = [i for i in range(1 , len(address_df) + 1)]\n",
    "\n",
    "surroundings_df = df[surroundings_id].copy().drop_duplicates()\n",
    "surroundings_df[\"surroundings_id\"] = [i for i in range(1 , len(surroundings_df) + 1)]\n",
    "\n",
    "transaction_df = df[transaction_id].copy().drop_duplicates()\n",
    "transaction_df[\"transaction_id\"] = [i for i in range(1 , len(transaction_df) + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resale_data = df.copy()\n",
    "resale_data[\"property_id\"] = resale_data[property_id].merge(property_df, how='left')['property_id']\n",
    "resale_data[\"address_id\"] = resale_data[address_id].merge(address_df, how='left')['address_id']\n",
    "resale_data[\"surroundings_id\"] = resale_data[surroundings_id].merge(surroundings_df, how='left')['surroundings_id']\n",
    "resale_data[\"transaction_id\"] = resale_data[transaction_id].merge(transaction_df, how='left')['transaction_id']\n",
    "\n",
    "# Drop the original columns that have been replaced\n",
    "resale_data.drop(property_id + address_id + surroundings_id + transaction_id, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"neural-hour-421815\"\n",
    "dataset_id = \"is3107\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects in bucket 'is3107_project':\n",
      "- knn_model.pkl\n",
      "- linear_model.pkl\n",
      "- linear_model_new.pkl\n"
     ]
    }
   ],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(CREDS)\n",
    "\n",
    "storage_client = storage.Client(credentials=credentials)\n",
    "# Define the name of the GCS bucket and the local path to the pickle file\n",
    "bucket_name = 'is3107_project'\n",
    "# Get the specified bucket\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # List all objects (items) in the bucket\n",
    "print(f\"Objects in bucket '{bucket_name}':\")\n",
    "blobs = list(bucket.list_blobs())\n",
    "if blobs:\n",
    "    for blob in blobs:\n",
    "        print(f\"- {blob.name}\")\n",
    "else:\n",
    "    print(\"No objects found in the bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717069 out of 717069 rows loaded.\u001b[0mm] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 661.35it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717069 out of 717069 rows loaded.\u001b[0mm] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 291.35it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105740 out of 105740 rows loaded.\u001b[0mm] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.91it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9013 out of 9013 rows loaded.\u001b[0m0\u001b[0m] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 418.38it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8992 out of 8992 rows loaded.\u001b[0m0\u001b[0m] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 471.27it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158174 out of 158174 rows loaded.\u001b[0mm] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 413.56it/s]\n"
     ]
    }
   ],
   "source": [
    "table_id = \"resale_price\"   # Table ID within the specified dataset\n",
    "df.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717069 out of 717069 rows loaded.\u001b[0mm] {\u001b[34mgbq.py:\u001b[0m515} INFO\u001b[0m - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 272.11it/s]\n"
     ]
    }
   ],
   "source": [
    "        # Upload DataFrame to BigQuery\n",
    "table_id = \"resale_data\"   # Table ID within the specified dataset\n",
    "resale_data.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Dataset ID and table name\n",
    "table_id = \"Property_new\"   # Table ID within the specified dataset\n",
    "\n",
    "        # Upload DataFrame to BigQuery\n",
    "property_df.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n",
    "        \n",
    "        # Dataset ID and table name\n",
    "table_id = \"Address_new\"   # Table ID within the specified dataset\n",
    "\n",
    "        # Upload DataFrame to BigQuery\n",
    "address_df.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n",
    "        \n",
    "        # Dataset ID and table name\n",
    "table_id = \"Surroundings_new\"   # Table ID within the specified dataset\n",
    "\n",
    "        # Upload DataFrame to BigQuery\n",
    "surroundings_df.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n",
    "        \n",
    "        # Dataset ID and table name\n",
    "table_id = \"Transaction_new\"   # Table ID within the specified dataset\n",
    "\n",
    "        # Upload DataFrame to BigQuery\n",
    "transaction_df.to_gbq(destination_table=f\"{project_id}.{dataset_id}.{table_id}\", project_id=project_id, if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
